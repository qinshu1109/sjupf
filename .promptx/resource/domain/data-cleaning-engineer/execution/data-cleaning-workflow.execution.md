<execution>
  <constraint>
    ## 数据清洗技术约束
    - **文件格式限制**：主要处理Excel文件(.xlsx)，需要考虑文件大小限制
    - **内存限制**：本地运行环境的内存限制，大文件需要分块处理
    - **Streamlit限制**：文件上传大小限制，会话状态管理限制
    - **依赖库约束**：仅使用pandas、openpyxl、tqdm等基础库
    - **离线运行**：不依赖外部API，完全本地化处理
  </constraint>

  <rule>
    ## 数据清洗强制规则
    - **数据完整性**：确保关键字段不丢失，保持数据的业务逻辑完整性
    - **标准化一致性**：所有输出数据必须遵循统一的字段命名和格式标准
    - **错误处理**：对于无法处理的数据必须记录并提供明确的错误信息
    - **性能要求**：单个文件处理时间不超过合理范围，提供进度反馈
    - **结果可验证**：提供数据预览和统计信息，让用户能够验证处理结果
  </rule>

  <guideline>
    ## 数据清洗指导原则
    - **用户友好**：优先考虑用户体验，提供清晰的操作指导和反馈
    - **容错设计**：对于常见的数据质量问题提供自动修复或智能建议
    - **可配置性**：允许用户自定义字段映射和处理规则
    - **透明度**：让用户了解数据处理的过程和结果
    - **可扩展性**：设计时考虑未来新数据源和处理需求的扩展
  </guideline>

  <process>
    ## 数据清洗标准流程
    
    ### Phase 1: 数据输入与验证
    ```mermaid
    flowchart TD
        A[文件上传] --> B{文件格式检查}
        B -->|Excel格式| C[文件大小检查]
        B -->|非Excel| D[格式错误提示]
        C -->|<50MB| E[读取文件结构]
        C -->|≥50MB| F[大文件警告]
        F --> E
        E --> G[字段识别]
        G --> H[显示字段映射预览]
    ```
    
    **关键步骤**：
    1. **文件验证**：检查文件格式、大小、可读性
    2. **结构分析**：识别表头、数据行、字段类型
    3. **字段映射**：自动匹配标准字段，显示映射关系
    4. **用户确认**：允许用户调整字段映射
    
    ### Phase 2: 数据清洗与标准化
    ```mermaid
    flowchart TD
        A[开始清洗] --> B[字段重命名]
        B --> C[数据类型转换]
        C --> D[数值标准化]
        D --> E[派生字段计算]
        E --> F[无效数据处理]
        F --> G[质量检查]
        G --> H[生成清洗报告]
    ```
    
    **核心处理逻辑**：
    1. **字段重命名**：根据映射关系重命名列
    2. **数值标准化**：调用numeric_normalizer处理数值格式
    3. **派生字段**：从文件名提取rank_type、snapshot_tag、source_table
    4. **数据清理**：删除无关列，处理缺失值
    5. **质量验证**：检查数据完整性和一致性
    
    ### Phase 3: 结果输出与展示
    ```mermaid
    flowchart TD
        A[处理完成] --> B[生成预览]
        B --> C[创建下载包]
        C --> D[显示统计信息]
        D --> E[提供下载链接]
        E --> F[清理临时文件]
    ```
    
    **输出处理**：
    1. **数据预览**：显示前10行处理结果
    2. **统计报告**：显示处理文件数、记录数、错误数
    3. **打包下载**：将所有处理结果打包为ZIP文件
    4. **临时清理**：处理完成后清理临时文件
    
    ## 错误处理策略
    
    ### 文件级错误处理
    ```mermaid
    graph TD
        A[文件处理] --> B{是否成功}
        B -->|成功| C[加入结果集]
        B -->|失败| D[记录错误信息]
        D --> E[继续处理下一个]
        C --> F[更新进度]
        E --> F
        F --> G{还有文件?}
        G -->|是| A
        G -->|否| H[生成最终报告]
    ```
    
    ### 数据级错误处理
    - **字段缺失**：记录缺失字段，使用默认值或空值
    - **格式错误**：记录错误行，尝试自动修复或跳过
    - **数值异常**：标记异常值，提供处理建议
    - **编码问题**：自动检测编码，提供转换选项
    
    ## 性能优化策略
    
    ### 内存管理
    - **分块读取**：大文件分块处理，避免内存溢出
    - **及时释放**：处理完成后及时释放DataFrame内存
    - **缓存策略**：合理使用Streamlit缓存机制
    
    ### 处理效率
    - **并行处理**：多文件并行处理（在内存允许的情况下）
    - **向量化操作**：使用pandas向量化操作提高效率
    - **进度反馈**：使用tqdm提供详细的进度信息
  </process>

  <criteria>
    ## 数据清洗质量标准
    
    ### 数据完整性
    - ✅ 所有标准字段都有对应的处理逻辑
    - ✅ 关键业务字段不丢失
    - ✅ 数据行数与原始文件一致（除非有明确的过滤规则）
    - ✅ 字段映射关系准确无误
    
    ### 数据准确性
    - ✅ 数值转换结果正确
    - ✅ 派生字段计算逻辑正确
    - ✅ 数据类型转换无错误
    - ✅ 特殊值处理符合业务逻辑
    
    ### 处理效率
    - ✅ 单个文件处理时间合理
    - ✅ 内存使用控制在合理范围
    - ✅ 进度反馈及时准确
    - ✅ 错误处理不影响整体流程
    
    ### 用户体验
    - ✅ 操作流程简单直观
    - ✅ 错误信息清晰易懂
    - ✅ 结果展示完整有用
    - ✅ 下载功能稳定可靠
  </criteria>
</execution>
