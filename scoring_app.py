#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”µå•†æ•°æ®æ™ºèƒ½è¿‡æ»¤è¯„åˆ†ç³»ç»Ÿ - Streamlit Webåº”ç”¨
åŸºäºscore_select.pyçš„Webç•Œé¢ç‰ˆæœ¬
"""

import streamlit as st
import pandas as pd
import numpy as np
import io
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ç°æœ‰çš„è¯„åˆ†è„šæœ¬
try:
    import score_select as ss
except ImportError:
    st.error("âŒ æ— æ³•å¯¼å…¥score_select.pyï¼Œè¯·ç¡®ä¿æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
    st.stop()

def configure_page():
    """é…ç½®é¡µé¢è®¾ç½®"""
    st.set_page_config(
        page_title="ç”µå•†æ•°æ®æ™ºèƒ½è¯„åˆ†ç³»ç»Ÿ",
        page_icon="ğŸ¯",
        layout="wide",
        initial_sidebar_state="expanded"
    )

def display_header():
    """æ˜¾ç¤ºé¡µé¢æ ‡é¢˜å’Œè¯´æ˜"""
    st.title("ğŸ¯ ç”µå•†æ•°æ®æ™ºèƒ½è¿‡æ»¤è¯„åˆ†ç³»ç»Ÿ")
    st.markdown("""
    **åŠŸèƒ½è¯´æ˜**ï¼šé€šè¿‡8å¤§è¯„åˆ†ç®—æ³•å’ŒèŠ‚æ—¥æ¨¡å¼æ„ŸçŸ¥ï¼Œä»ç”µå•†æ•°æ®ä¸­æ™ºèƒ½ç­›é€‰TOP50é«˜ä»·å€¼å•†å“
    
    **æ”¯æŒæ ¼å¼**ï¼šCSVã€XLSXæ–‡ä»¶ | **è¾“å‡º**ï¼šTOP50å•†å“æ’è¡Œæ¦œ + è¯„åˆ†è¯¦æƒ…
    """)
    st.divider()

def create_sidebar():
    """åˆ›å»ºä¾§è¾¹æ æ§ä»¶"""
    st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ä¸é…ç½®")
    
    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_files = st.sidebar.file_uploader(
        "ä¸Šä¼ æ¸…æ´—åçš„æ•°æ®æ–‡ä»¶",
        type=['csv', 'xlsx'],
        accept_multiple_files=True,
        help="æ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªCSVæˆ–XLSXæ–‡ä»¶"
    )
    
    # èŠ‚æ—¥æ¨¡å¼å¼€å…³
    holiday_mode = st.sidebar.checkbox(
        "ğŸ„ èŠ‚æ—¥åŠ æƒ (Holiday Boost)",
        value=True,
        help="å¯ç”¨åå°†åœ¨è·ç¦»èŠ‚æ—¥45å¤©å†…è‡ªåŠ¨è°ƒæ•´æƒé‡"
    )
    
    # å¼€å§‹è¯„åˆ†æŒ‰é’®
    start_scoring = st.sidebar.button(
        "ğŸš€ å¼€å§‹è¯„åˆ†",
        type="primary",
        use_container_width=True
    )
    
    # æ˜¾ç¤ºç®—æ³•è¯´æ˜
    with st.sidebar.expander("ğŸ“Š è¯„åˆ†ç®—æ³•è¯´æ˜"):
        st.markdown("""
        **8å¤§è¯„åˆ†ç»´åº¦**ï¼š
        - ğŸ“ˆ é”€é‡/GMVè¡¨ç° (é•¿å°¾æˆªæ–­)
        - ğŸ’° ä½£é‡‘æ¿€åŠ± (åˆ†æ®µè¯„åˆ†)
        - ğŸ‘¥ è¾¾äººå½±å“åŠ› (ä½™å¼¦è¡°å‡)
        - ğŸ† æ’åè¡¨ç° (æŒ‡æ•°è¡°å‡)
        - ğŸ“Š å¢é•¿æ½œåŠ› (åŠ¨æ€è¯„ä¼°)
        - ğŸ”„ æ¸ é“åˆ†å¸ƒ (å¤šå…ƒåŒ–)
        - âœ… è½¬åŒ–æ•ˆç‡ (è´¨é‡é—¨æ§›)
        - ğŸ„ èŠ‚æ—¥æ„ŸçŸ¥ (æ™ºèƒ½è°ƒæƒ)
        """)
    
    return uploaded_files, holiday_mode, start_scoring

def read_uploaded_file(uploaded_file):
    """è¯»å–ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        if uploaded_file.name.endswith('.xlsx'):
            df = pd.read_excel(uploaded_file)
        else:
            # å°è¯•ä¸åŒç¼–ç è¯»å–CSV
            content = uploaded_file.read()
            for encoding in ['utf-8', 'gbk', 'gb2312']:
                try:
                    df = pd.read_csv(io.StringIO(content.decode(encoding)))
                    break
                except:
                    continue
            else:
                df = pd.read_csv(io.StringIO(content.decode('utf-8', errors='ignore')))
        
        return df
    except Exception as e:
        st.error(f"âŒ è¯»å–æ–‡ä»¶ {uploaded_file.name} å¤±è´¥: {str(e)}")
        return None

def validate_data_format(df, filename):
    """éªŒè¯æ•°æ®æ ¼å¼ï¼ˆæ”¯æŒåŠ¨æ€å­—æ®µæ£€æŸ¥ï¼‰"""
    # æ ¸å¿ƒå¿…éœ€å­—æ®µï¼ˆç»å¯¹ä¸èƒ½ç¼ºå°‘ï¼‰
    core_required_columns = [
        'product_name', 'product_url', 'category_l1', 'commission',
        'conv_30d', 'rank_type', 'rank_no', 'influencer_7d'
    ]

    # é”€é‡/GMVå­—æ®µç»„ï¼ˆè‡³å°‘éœ€è¦ä¸€ç»„å®Œæ•´çš„7å¤©æˆ–30å¤©æ•°æ®ï¼‰
    sales_gmv_7d = ['sales_7d', 'gmv_7d']
    sales_gmv_30d = ['sales_30d', 'gmv_30d']

    # å¯é€‰å­—æ®µï¼ˆç¼ºå¤±æ—¶ä¼šè­¦å‘Šä½†ä¸é˜»æ–­å¤„ç†ï¼‰
    optional_columns = [
        'live_gmv_30d', 'live_gmv_7d', 'card_gmv_30d',
        'sales_1y', 'snapshot_tag', 'file_date', 'data_period'
    ]

    # æ£€æŸ¥æ ¸å¿ƒå¿…éœ€å­—æ®µ
    missing_core = [col for col in core_required_columns if col not in df.columns]
    if missing_core:
        st.error(f"âŒ æ–‡ä»¶ {filename} ç¼ºå°‘æ ¸å¿ƒå¿…éœ€å­—æ®µ: {', '.join(missing_core)}")
        return False

    # æ£€æŸ¥é”€é‡/GMVå­—æ®µç»„
    has_7d_data = all(col in df.columns for col in sales_gmv_7d)
    has_30d_data = all(col in df.columns for col in sales_gmv_30d)

    if not has_7d_data and not has_30d_data:
        st.error(f"âŒ æ–‡ä»¶ {filename} ç¼ºå°‘é”€é‡/GMVæ•°æ®ï¼šéœ€è¦è‡³å°‘ä¸€ç»„å®Œæ•´çš„7å¤©æˆ–30å¤©æ•°æ®")
        return False

    # æ£€æŸ¥å¯é€‰å­—æ®µå¹¶ç»™å‡ºè­¦å‘Š
    missing_optional = [col for col in optional_columns if col not in df.columns]
    if missing_optional:
        st.warning(f"âš ï¸ æ–‡ä»¶ {filename} ç¼ºå°‘å¯é€‰å­—æ®µ: {', '.join(missing_optional)}ï¼ˆå°†ä½¿ç”¨é»˜è®¤å€¼ï¼‰")

    # æ˜¾ç¤ºæ•°æ®å®Œæ•´æ€§ä¿¡æ¯
    if has_7d_data and has_30d_data:
        st.success(f"âœ… æ–‡ä»¶ {filename} åŒ…å«å®Œæ•´çš„7å¤©å’Œ30å¤©æ•°æ®")
    elif has_30d_data:
        st.info(f"â„¹ï¸ æ–‡ä»¶ {filename} ä»…åŒ…å«30å¤©æ•°æ®ï¼Œå°†å¯ç”¨åŠ¨æ€æƒé‡è°ƒæ•´")
    elif has_7d_data:
        st.info(f"â„¹ï¸ æ–‡ä»¶ {filename} ä»…åŒ…å«7å¤©æ•°æ®ï¼Œå°†å¯ç”¨åŠ¨æ€æƒé‡è°ƒæ•´")

    return True

def preprocess_missing_fields(df):
    """é¢„å¤„ç†ç¼ºå¤±å­—æ®µï¼Œè¡¥å…¨å¿…è¦çš„æ•°å€¼åˆ—"""
    df = df.copy()

    # å®šä¹‰æ‰€æœ‰å¯èƒ½éœ€è¦çš„æ•°å€¼å­—æ®µåŠå…¶é»˜è®¤å€¼
    numeric_fields_defaults = {
        'sales_7d': 0,
        'gmv_7d': 0,
        'sales_30d': 0,
        'gmv_30d': 0,
        'live_gmv_30d': 0,
        'live_gmv_7d': 0,
        'card_gmv_30d': 0,
        'sales_1y': 0,
        'rank_no': 999,  # é»˜è®¤æ’åå¾ˆä½
    }

    # å®šä¹‰æ–‡æœ¬å­—æ®µåŠå…¶é»˜è®¤å€¼
    text_fields_defaults = {
        'snapshot_tag': 'æ•°æ®è¡¥å…¨',
        'file_date': datetime.now().strftime('%Y-%m-%d'),
        'data_period': '30å¤©'
    }

    # è¡¥å…¨ç¼ºå¤±çš„æ•°å€¼å­—æ®µ
    for field, default_value in numeric_fields_defaults.items():
        if field not in df.columns:
            df[field] = default_value
            st.info(f"ğŸ“ è¡¥å…¨ç¼ºå¤±å­—æ®µ {field}ï¼Œä½¿ç”¨é»˜è®¤å€¼: {default_value}")

    # è¡¥å…¨ç¼ºå¤±çš„æ–‡æœ¬å­—æ®µ
    for field, default_value in text_fields_defaults.items():
        if field not in df.columns:
            df[field] = default_value

    # æ™ºèƒ½ä¼°ç®—ï¼šåŸºäºç°æœ‰æ•°æ®è¡¥å…¨ç›¸å…³å­—æ®µ
    if 'live_gmv_7d' not in df.columns or df['live_gmv_7d'].sum() == 0:
        if 'gmv_7d' in df.columns and df['gmv_7d'].sum() > 0:
            df['live_gmv_7d'] = df['gmv_7d'] * 0.3  # å‡è®¾30%æ¥è‡ªç›´æ’­
            st.info("ğŸ“Š åŸºäº7å¤©GMVä¼°ç®—live_gmv_7dï¼ˆ30%æ¯”ä¾‹ï¼‰")
        elif 'live_gmv_30d' in df.columns and df['live_gmv_30d'].sum() > 0:
            df['live_gmv_7d'] = df['live_gmv_30d'] * 0.23  # 7/30 â‰ˆ 0.23
            st.info("ğŸ“Š åŸºäº30å¤©ç›´æ’­GMVä¼°ç®—live_gmv_7d")

    if 'card_gmv_30d' not in df.columns or df['card_gmv_30d'].sum() == 0:
        if 'gmv_30d' in df.columns and df['gmv_30d'].sum() > 0:
            df['card_gmv_30d'] = df['gmv_30d'] * 0.2  # å‡è®¾20%æ¥è‡ªå•†å“å¡
            st.info("ğŸ“Š åŸºäº30å¤©GMVä¼°ç®—card_gmv_30dï¼ˆ20%æ¯”ä¾‹ï¼‰")

    if 'sales_1y' not in df.columns or df['sales_1y'].sum() == 0:
        if 'sales_30d' in df.columns and df['sales_30d'].sum() > 0:
            df['sales_1y'] = df['sales_30d'] * 12
            st.info("ğŸ“Š åŸºäº30å¤©é”€é‡ä¼°ç®—å¹´é”€é‡")
        elif 'sales_7d' in df.columns and df['sales_7d'].sum() > 0:
            df['sales_1y'] = df['sales_7d'] * 52
            st.info("ğŸ“Š åŸºäº7å¤©é”€é‡ä¼°ç®—å¹´é”€é‡")

    return df

def score_dataframe(df, holiday_mode=True):
    """å¯¹DataFrameè¿›è¡Œè¯„åˆ†å¤„ç†ï¼ˆæ”¯æŒç¼ºå¤±å­—æ®µï¼‰"""
    try:
        # æ•°æ®é¢„å¤„ç†ï¼šè¡¥å…¨ç¼ºå¤±çš„æ•°å€¼å­—æ®µ
        df = preprocess_missing_fields(df)

        # å¤„ç†æ•°æ®ï¼ˆæ—¥æœŸè§£æå’ŒèŠ‚æ—¥æ¨¡å¼æ£€æµ‹åœ¨process_single_fileå†…éƒ¨å®Œæˆï¼‰
        processed_df = ss.process_single_file(df, None, False)

        if len(processed_df) == 0:
            return processed_df, False, 999

        # ä»å¤„ç†åçš„æ•°æ®ä¸­è·å–èŠ‚æ—¥æ¨¡å¼ä¿¡æ¯ï¼ˆé€šè¿‡é‡æ–°è§£ææ—¥æœŸï¼‰
        if 'file_date' in df.columns and len(df) > 0:
            raw_file_date = df['file_date'].iloc[0]
            parsed_file_date = ss.parse_file_date(raw_file_date)
            days_to_holiday = ss.calculate_days_to_next_holiday(parsed_file_date)
            is_holiday_mode = holiday_mode and days_to_holiday <= 45
        else:
            days_to_holiday = 999
            is_holiday_mode = False

        return processed_df, is_holiday_mode, days_to_holiday

    except Exception as e:
        st.error(f"âŒ æ•°æ®è¯„åˆ†å¤„ç†å¤±è´¥: {str(e)}")
        return pd.DataFrame(), False, 999

def process_files(uploaded_files, holiday_mode):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    if not uploaded_files:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        return None
    
    all_results = []
    total_original_rows = 0
    total_processed_rows = 0
    holiday_files = 0
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, uploaded_file in enumerate(uploaded_files):
        # æ›´æ–°è¿›åº¦
        progress = (i + 1) / len(uploaded_files)
        progress_bar.progress(progress)
        status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
        
        # è¯»å–æ–‡ä»¶
        df = read_uploaded_file(uploaded_file)
        if df is None:
            continue
        
        # éªŒè¯æ ¼å¼
        if not validate_data_format(df, uploaded_file.name):
            continue
        
        original_rows = len(df)
        total_original_rows += original_rows
        
        # è¯„åˆ†å¤„ç†
        processed_df, is_holiday_mode, days_to_holiday = score_dataframe(df, holiday_mode)
        
        if len(processed_df) > 0:
            all_results.append(processed_df)
            total_processed_rows += len(processed_df)
            
            if is_holiday_mode:
                holiday_files += 1
                st.success(f"âœ… {uploaded_file.name}: {len(processed_df)}/{original_rows} è¡Œæœ‰æ•ˆ (èŠ‚æ—¥æ¨¡å¼: è·ç¦»ä¸‹ä¸€èŠ‚æ—¥ {days_to_holiday} å¤©)")
            else:
                st.info(f"â„¹ï¸ {uploaded_file.name}: {len(processed_df)}/{original_rows} è¡Œæœ‰æ•ˆ (æ ‡å‡†æ¨¡å¼)")
        else:
            st.warning(f"âš ï¸ {uploaded_file.name}: å¤„ç†åæ— æœ‰æ•ˆæ•°æ®")
    
    # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
    progress_bar.empty()
    status_text.empty()
    
    if not all_results:
        st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯å¤„ç†")
        return None
    
    # åˆå¹¶ç»“æœ
    combined_df = pd.concat(all_results, ignore_index=True)
    
    # å»é‡å’Œæ’åº
    before_dedup = len(combined_df)
    combined_df = combined_df.drop_duplicates(subset=['product_url'], keep='first')
    after_dedup = len(combined_df)
    
    # å–TOP50
    top50_df = combined_df.nlargest(50, 'total_score')
    
    # ä¿æŒåŸå­—æ®µç»“æ„
    original_cols = [
        'product_name', 'product_url', 'category_l1', 'commission',
        'sales_7d', 'gmv_7d', 'sales_30d', 'gmv_30d',
        'live_gmv_30d', 'live_gmv_7d', 'card_gmv_30d',
        'sales_1y', 'conv_30d', 'rank_type', 'rank_no', 
        'influencer_7d', 'snapshot_tag', 'file_date', 'data_period'
    ]
    
    output_cols = [col for col in original_cols if col in top50_df.columns] + ['total_score']
    top50_df = top50_df[output_cols]
    
    # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
    st.success(f"""
    ğŸ“Š **å¤„ç†å®Œæˆç»Ÿè®¡**
    - å¤„ç†æ–‡ä»¶æ•°: {len(uploaded_files)}
    - èŠ‚æ—¥æ¨¡å¼æ–‡ä»¶: {holiday_files}
    - åŸå§‹æ•°æ®è¡Œæ•°: {total_original_rows:,}
    - æœ‰æ•ˆæ•°æ®è¡Œæ•°: {total_processed_rows:,}
    - å»é‡å‰: {before_dedup:,} â†’ å»é‡å: {after_dedup:,}
    - æœ€ç»ˆTOP50å•†å“å·²ç”Ÿæˆ
    """)
    
    return top50_df

def display_results(top50_df):
    """æ˜¾ç¤ºç»“æœ"""
    if top50_df is None or len(top50_df) == 0:
        return
    
    st.header("ğŸ† TOP50 å•†å“æ’è¡Œæ¦œ")
    
    # æ˜¾ç¤ºå…³é”®ç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("å•†å“æ•°é‡", len(top50_df))
    with col2:
        st.metric("æœ€é«˜è¯„åˆ†", f"{top50_df['total_score'].max():.4f}")
    with col3:
        st.metric("å¹³å‡è¯„åˆ†", f"{top50_df['total_score'].mean():.4f}")
    with col4:
        st.metric("æœ€ä½è¯„åˆ†", f"{top50_df['total_score'].min():.4f}")
    
    # æ˜¾ç¤ºæ•°æ®è¡¨
    st.dataframe(
        top50_df,
        use_container_width=True,
        height=400,
        column_config={
            "total_score": st.column_config.NumberColumn(
                "æ€»è¯„åˆ†",
                help="ç»¼åˆ8å¤§ç»´åº¦çš„åŠ æƒè¯„åˆ†",
                format="%.4f"
            ),
            "commission": st.column_config.NumberColumn(
                "ä½£é‡‘ç‡",
                format="%.3f"
            ),
            "conv_30d": st.column_config.NumberColumn(
                "è½¬åŒ–ç‡",
                format="%.3f"
            )
        }
    )
    
    # ä¸‹è½½æŒ‰é’®
    csv_data = top50_df.to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½TOP50ç»“æœ (CSV)",
        data=csv_data,
        file_name=f"top50_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
        use_container_width=True
    )

def main():
    """ä¸»å‡½æ•°"""
    configure_page()
    display_header()
    
    # åˆ›å»ºä¾§è¾¹æ 
    uploaded_files, holiday_mode, start_scoring = create_sidebar()
    
    # ä¸»è¦å¤„ç†é€»è¾‘
    if start_scoring:
        with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®ï¼Œè¯·ç¨å€™..."):
            try:
                top50_df = process_files(uploaded_files, holiday_mode)
                if top50_df is not None:
                    st.session_state['results'] = top50_df
            except Exception as e:
                st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    # æ˜¾ç¤ºç»“æœ
    if 'results' in st.session_state:
        display_results(st.session_state['results'])
    else:
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.info("""
        ### ğŸ“‹ ä½¿ç”¨è¯´æ˜
        
        1. **ä¸Šä¼ æ•°æ®**: åœ¨å·¦ä¾§ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªæ¸…æ´—åçš„CSV/XLSXæ–‡ä»¶
        2. **é…ç½®é€‰é¡¹**: é€‰æ‹©æ˜¯å¦å¯ç”¨èŠ‚æ—¥åŠ æƒæ¨¡å¼
        3. **å¼€å§‹è¯„åˆ†**: ç‚¹å‡»"å¼€å§‹è¯„åˆ†"æŒ‰é’®å¤„ç†æ•°æ®
        4. **æŸ¥çœ‹ç»“æœ**: ç³»ç»Ÿå°†æ˜¾ç¤ºTOP50å•†å“æ’è¡Œæ¦œ
        5. **ä¸‹è½½ç»“æœ**: å¯ä¸‹è½½CSVæ ¼å¼çš„è¯„åˆ†ç»“æœ
        
        **æ•°æ®è¦æ±‚**: æ–‡ä»¶éœ€åŒ…å«19ä¸ªæ ‡å‡†å­—æ®µï¼ŒåŒ…æ‹¬å•†å“ä¿¡æ¯ã€é”€é‡æ•°æ®ã€GMVæ•°æ®ç­‰
        """)

if __name__ == "__main__":
    main()
