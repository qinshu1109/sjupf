#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•é‡å¤åˆ—åä¿®å¤åŠŸèƒ½
"""

import pandas as pd
import os

def create_duplicate_column_test_files():
    """åˆ›å»ºåŒ…å«é‡å¤åˆ—åé—®é¢˜çš„æµ‹è¯•æ–‡ä»¶"""
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•
    if not os.path.exists('test_duplicate'):
        os.makedirs('test_duplicate')
    
    # æµ‹è¯•æ¡ˆä¾‹1ï¼šåŸå§‹æ•°æ®ä¸­æœ‰é‡å¤åˆ—å
    test_data_1 = {
        'å•†å“': ['iPhone 15', 'åä¸ºMate60', 'å°ç±³14'],
        'å•†å“åˆ†ç±»': ['æ‰‹æœºæ•°ç ', 'æ‰‹æœºæ•°ç ', 'æ‰‹æœºæ•°ç '],
        'åˆ†ç±»': ['æ‰‹æœºæ•°ç ', 'æ‰‹æœºæ•°ç ', 'æ‰‹æœºæ•°ç '],  # è¿™ä¼šæ˜ å°„åˆ°åŒä¸€ä¸ªæ ‡å‡†å­—æ®µ
        'ä½£é‡‘æ¯”ä¾‹': ['15%', '12%', '18%'],
        'ä½£é‡‘': ['15%', '12%', '18%'],  # è¿™ä¹Ÿä¼šæ˜ å°„åˆ°åŒä¸€ä¸ªæ ‡å‡†å­—æ®µ
        'è¿‘7å¤©é”€é‡': ['1.2w', '8500', '2.5w']
    }
    
    df1 = pd.DataFrame(test_data_1)
    df1.to_csv('test_duplicate/duplicate_mapping_fields.csv', index=False, encoding='utf-8')
    print("âœ… åˆ›å»ºé‡å¤æ˜ å°„å­—æ®µæµ‹è¯•æ–‡ä»¶: duplicate_mapping_fields.csv")
    
    # æµ‹è¯•æ¡ˆä¾‹2ï¼šç›´æ¥åŒ…å«é‡å¤åˆ—åçš„CSV
    test_data_2 = {
        'å•†å“': ['Nike Air Max', 'Adidas Ultra Boost', 'New Balance 990'],
        'å•†å“é“¾æ¥': ['https://douyin.com/1', 'https://douyin.com/2', 'https://douyin.com/3'],
        'å•†å“åˆ†ç±»': ['è¿åŠ¨é‹æœ', 'è¿åŠ¨é‹æœ', 'è¿åŠ¨é‹æœ']
    }
    
    df2 = pd.DataFrame(test_data_2)
    # æ‰‹åŠ¨æ·»åŠ é‡å¤åˆ—å
    df2['å•†å“åˆ†ç±»_duplicate'] = df2['å•†å“åˆ†ç±»']
    df2.columns = ['å•†å“', 'å•†å“é“¾æ¥', 'å•†å“åˆ†ç±»', 'å•†å“åˆ†ç±»']  # å¼ºåˆ¶åˆ›å»ºé‡å¤åˆ—å
    
    df2.to_csv('test_duplicate/direct_duplicate_columns.csv', index=False, encoding='utf-8')
    print("âœ… åˆ›å»ºç›´æ¥é‡å¤åˆ—åæµ‹è¯•æ–‡ä»¶: direct_duplicate_columns.csv")
    
    # æµ‹è¯•æ¡ˆä¾‹3ï¼šå¤šç§åˆ«åæ˜ å°„åˆ°åŒä¸€å­—æ®µ
    test_data_3 = {
        'å•†å“åç§°': ['æˆ´æ£®å¹é£æœº', 'é›…è¯—å…°é»›é¢éœœ', 'å…°è”»ç²¾å'],
        'äº§å“å': ['æˆ´æ£®å¹é£æœº', 'é›…è¯—å…°é»›é¢éœœ', 'å…°è”»ç²¾å'],  # éƒ½ä¼šæ˜ å°„åˆ°product_name
        'å•†å“': ['æˆ´æ£®å¹é£æœº', 'é›…è¯—å…°é»›é¢éœœ', 'å…°è”»ç²¾å'],    # éƒ½ä¼šæ˜ å°„åˆ°product_name
        'ä¸€çº§åˆ†ç±»': ['ç¾å¦†æŠ¤è‚¤', 'ç¾å¦†æŠ¤è‚¤', 'ç¾å¦†æŠ¤è‚¤'],
        'å•†å“åˆ†ç±»': ['ç¾å¦†æŠ¤è‚¤', 'ç¾å¦†æŠ¤è‚¤', 'ç¾å¦†æŠ¤è‚¤'],      # éƒ½ä¼šæ˜ å°„åˆ°category_l1
        'åˆ†ç±»': ['ç¾å¦†æŠ¤è‚¤', 'ç¾å¦†æŠ¤è‚¤', 'ç¾å¦†æŠ¤è‚¤'],          # éƒ½ä¼šæ˜ å°„åˆ°category_l1
        'ä½£é‡‘æ¯”ä¾‹': ['25%', '30%', '28%']
    }
    
    df3 = pd.DataFrame(test_data_3)
    df3.to_csv('test_duplicate/multiple_aliases.csv', index=False, encoding='utf-8')
    print("âœ… åˆ›å»ºå¤šåˆ«åæ˜ å°„æµ‹è¯•æ–‡ä»¶: multiple_aliases.csv")
    
    print(f"\nğŸ¯ é‡å¤åˆ—åæµ‹è¯•æ–‡ä»¶åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“‚ ä½ç½®: test_duplicate/ ç›®å½•")
    print(f"\nğŸ’¡ è¿™äº›æ–‡ä»¶å¯ä»¥ç”¨æ¥æµ‹è¯•:")
    print(f"   â€¢ å­—æ®µæ˜ å°„æ—¶çš„é‡å¤åˆ—åå¤„ç†")
    print(f"   â€¢ ç›´æ¥é‡å¤åˆ—åçš„å»é‡åŠŸèƒ½")
    print(f"   â€¢ å¤šä¸ªåˆ«åæ˜ å°„åˆ°åŒä¸€æ ‡å‡†å­—æ®µçš„å¤„ç†")

def test_smart_field_mapping():
    """æµ‹è¯•æ™ºèƒ½å­—æ®µæ˜ å°„å‡½æ•°çš„é‡å¤å¤„ç†"""
    
    # æ¨¡æ‹ŸFIELD_ALIASES
    FIELD_ALIASES = {
        'product_name': ['å•†å“', 'å•†å“åç§°', 'äº§å“å', 'å•†å“æ ‡é¢˜', 'åç§°'],
        'category_l1': ['å•†å“åˆ†ç±»', 'åˆ†ç±»', 'ä¸€çº§åˆ†ç±»', 'ç±»ç›®'],
        'commission': ['ä½£é‡‘æ¯”ä¾‹', 'ä½£é‡‘', 'ææˆæ¯”ä¾‹', 'åˆ†æˆ']
    }
    
    def smart_field_mapping(columns):
        """ç®€åŒ–ç‰ˆçš„æ™ºèƒ½å­—æ®µæ˜ å°„å‡½æ•°"""
        mapping = {}
        used_std_fields = set()
        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…
        for std_field, aliases in FIELD_ALIASES.items():
            if std_field in used_std_fields:
                continue
                
            for col in columns:
                if col in aliases:
                    mapping[col] = std_field
                    used_std_fields.add(std_field)
                    break
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        for std_field, aliases in FIELD_ALIASES.items():
            if std_field in used_std_fields:
                continue
                
            for col in columns:
                if col in mapping:
                    continue
                    
                for alias in aliases:
                    if alias in col or col in alias:
                        mapping[col] = std_field
                        used_std_fields.add(std_field)
                        break
                
                if std_field in used_std_fields:
                    break
        
        return mapping
    
    # æµ‹è¯•é‡å¤æ˜ å°„åœºæ™¯
    test_columns = ['å•†å“', 'å•†å“åç§°', 'äº§å“å', 'å•†å“åˆ†ç±»', 'åˆ†ç±»', 'ä½£é‡‘æ¯”ä¾‹', 'ä½£é‡‘']
    
    print("\nğŸ§ª æµ‹è¯•æ™ºèƒ½å­—æ®µæ˜ å°„é˜²é‡å¤åŠŸèƒ½")
    print(f"è¾“å…¥åˆ—å: {test_columns}")
    
    mapping = smart_field_mapping(test_columns)
    print(f"æ˜ å°„ç»“æœ: {mapping}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„æ ‡å‡†å­—æ®µ
    std_fields = list(mapping.values())
    duplicates = [field for field in set(std_fields) if std_fields.count(field) > 1]
    
    if duplicates:
        print(f"âŒ å‘ç°é‡å¤æ˜ å°„çš„æ ‡å‡†å­—æ®µ: {duplicates}")
    else:
        print("âœ… æ²¡æœ‰é‡å¤æ˜ å°„ï¼Œæµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    create_duplicate_column_test_files()
    test_smart_field_mapping()
